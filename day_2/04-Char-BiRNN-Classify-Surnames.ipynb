{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Surname Classification with BiDirectional RNNs\n",
    "\n",
    "## Dataset Info\n",
    "\n",
    "The surnames dataset has been collected from a couple different sources. \n",
    "\n",
    "#### Value Counts for the Nationality:\n",
    "\n",
    "```\n",
    "russian       9408\n",
    "english       3668\n",
    "arabic        2000\n",
    "japanese       991\n",
    "german         724\n",
    "italian        709\n",
    "czech          519\n",
    "spanish        298\n",
    "dutch          297\n",
    "french         277\n",
    "chinese        268\n",
    "irish          232\n",
    "greek          203\n",
    "polish         139\n",
    "scottish       100\n",
    "korean          94\n",
    "portuguese      74\n",
    "vietnamese      73\n",
    "Name: nationality, dtype: int64\n",
    "```\n",
    "\n",
    "## Model Info\n",
    "\n",
    "The `CharBiRNN` uses a BiDirectional RNN to get a feature vector for each character in each surname. These feature vectors are averaged. Then, the average feature vector is classified to its nationality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "from collections import Counter\n",
    "import json\n",
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = '4' \n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "from vocabulary import Vocabulary\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('fivethirtyeight')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "START_TOKEN = \"^\"\n",
    "END_TOKEN = \"_\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tokens(x_data_list):\n",
    "    \"\"\"Count the tokens in the data list\n",
    "    \n",
    "    Args:\n",
    "        x_data_list (list(list(str))): a list of lists, each sublist is a list of string tokens. \n",
    "            In other words, a list of the data points where the data points have been tokenized.\n",
    "    Returns:\n",
    "        dict: a mapping from tokens to their counts \n",
    "    \n",
    "    \"\"\"\n",
    "    # alternatively\n",
    "    # return Counter([token for x_data in x_data_list for token in x_data])\n",
    "    counter = Counter()\n",
    "    for x_data in x_data_list:\n",
    "        for token in x_data:\n",
    "            counter[token] += 1\n",
    "    return counter\n",
    "\n",
    "def add_splits(df, target_y_column, split_proportions=(0.7, 0.15, 0.15), seed=0):\n",
    "    \"\"\"Add 'train', 'val', and 'test' splits to the dataset\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): the data frame to assign splits to\n",
    "        target_y_column (str): the name of the label column; in order to\n",
    "            preserve the class distribution between splits, the label column\n",
    "            is used to group the datapoints and splits are assigned within these groups.\n",
    "        split_proportions (tuple(float, float, float)): three floats which represent the\n",
    "            proportion in 'train', 'val, 'and 'test'. Must sum to 1. \n",
    "        seed (int): the random seed for making the shuffling deterministic. If the dataset and seed\n",
    "            are kept the same, the split assignment is deterministic. \n",
    "    Returns:\n",
    "        pd.DataFrame: the input dataframe with a new column for split assignments; note: row order\n",
    "            will have changed.\n",
    "            \n",
    "    \"\"\"\n",
    "    df_by_label = {label: [] for label in df[target_y_column].unique()}\n",
    "    for _, row in df.iterrows():\n",
    "        df_by_label[row[target_y_column]].append(row.to_dict())\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    assert sum(split_proportions) == 1, \"`split_proportions` should sum to 1\"\n",
    "    train_p, val_p, test_p = split_proportions\n",
    "    \n",
    "    out_df = []\n",
    "    # to ensure consistent behavior, lexicographically sort the dictionary\n",
    "    for _, data_points in sorted(df_by_label.items()):\n",
    "        np.random.shuffle(data_points)\n",
    "        n_total = len(data_points)\n",
    "        n_train = int(train_p * n_total)\n",
    "        n_val = int(val_p * n_total)\n",
    "        \n",
    "        for data_point in data_points[:n_train]:\n",
    "            data_point['split'] = 'train'\n",
    "            \n",
    "        for data_point in data_points[n_train:n_train+n_val]:\n",
    "            data_point['split'] = 'val'\n",
    "            \n",
    "        for data_point in data_points[n_train+n_val:]:\n",
    "            data_point['split'] = 'test'\n",
    "        \n",
    "        out_df.extend(data_points)\n",
    "    \n",
    "    return pd.DataFrame(out_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised Text Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupervisedTextVectorizer:\n",
    "    \"\"\"A composite data structure that uses Vocabularies to map text and its labels to integers\n",
    "    \n",
    "    Attributes:\n",
    "        token_vocab (Vocabulary): the vocabulary managing the mapping between text tokens and \n",
    "            the unique indices that represent them\n",
    "        label_vocab (Vocabulary): the vocabulary managing the mapping between labels and the\n",
    "            unique indices that represent them.\n",
    "        max_seq_length (int): the length of the longest sequence (including start or end tokens\n",
    "            that will be prepended or appended).\n",
    "    \"\"\"\n",
    "    def __init__(self, token_vocab, label_vocab, max_seq_length):\n",
    "        \"\"\"Initialize the SupervisedTextVectorizer\n",
    "        \n",
    "        Args:\n",
    "            token_vocab (Vocabulary): the vocabulary managing the mapping between text tokens and \n",
    "                the unique indices that represent them\n",
    "            label_voab (Vocabulary): the vocabulary managing the mapping between labels and the\n",
    "                unique indices that represent them.\n",
    "            max_seq_length (int): the length of the longest sequence (including start or end tokens\n",
    "                that will be prepended or appended).\n",
    "        \"\"\"\n",
    "        self.token_vocab = token_vocab\n",
    "        self.label_vocab = label_vocab\n",
    "        self.max_seq_length = max_seq_length\n",
    "        \n",
    "    def _wrap_with_start_end(self, x_data):\n",
    "        \"\"\"Prepend the start token and append the end token.\n",
    "        \n",
    "        Args:\n",
    "            x_data (list(str)): the list of string tokens in the data point\n",
    "        Returns:\n",
    "            list(str): the list of string tokens with start token prepended and end token appended\n",
    "        \"\"\"\n",
    "        return [self.token_vocab.start_token] + x_data + [self.token_vocab.end_token]\n",
    "    \n",
    "    def vectorize(self, x_data, y_label):\n",
    "        \"\"\"Convert the data point and its label into their integer form\n",
    "        \n",
    "        Args:\n",
    "            x_data (list(str)): the list of string tokens in the data point\n",
    "            y_label (str,int): the label associated with the data point\n",
    "        Returns:\n",
    "            numpy.ndarray, int: x_data in vector form, padded to the max_seq_length; and \n",
    "                the label mapped to the integer that represents it\n",
    "        \"\"\"\n",
    "        x_data = self._wrap_with_start_end(x_data)\n",
    "        x_vector = np.zeros(self.max_seq_length).astype(np.int64)\n",
    "        x_data_indices = [self.token_vocab[token] for token in x_data]\n",
    "        x_vector[:len(x_data_indices)] = x_data_indices\n",
    "        y_index = self.label_vocab[y_label]\n",
    "        return x_vector, y_index\n",
    "    \n",
    "    def transform(self, x_data_list, y_label_list):\n",
    "        \"\"\"Transform a dataset by vectorizing each datapoint\n",
    "        \n",
    "        Args: \n",
    "            x_data_list (list(list(str))): a list of lists, each sublist contains string tokens\n",
    "            y_label_list (list(str,int)): a list of either strings or integers. the y label can come\n",
    "                as strings or integers, but they are remapped with the label_vocab to a unique integer\n",
    "        Returns:\n",
    "            np.ndarray(matrix), np.ndarray(vector): the vectorized x (matrix) and vectorized y (vector) \n",
    "        \"\"\"\n",
    "        x_matrix = []\n",
    "        y_vector = []\n",
    "        for x_data, y_label in zip(x_data_list, y_label_list):\n",
    "            x_vector, y_index = self.vectorize(x_data, y_label)\n",
    "            x_matrix.append(x_vector)\n",
    "            y_vector.append(y_index)\n",
    "        \n",
    "        return np.stack(x_matrix), np.stack(y_vector)\n",
    "    \n",
    "    @classmethod\n",
    "    def from_df(cls, df, target_x_column, target_y_column, token_count_cutoff=0):\n",
    "        \"\"\"Instantiate the SupervisedTextVectorizer from a standardized dataframe\n",
    "        \n",
    "        Standardized DataFrame has a special meaning:\n",
    "            there is a column that has been tokenized into a list of strings\n",
    "        \n",
    "        Args:\n",
    "            df (pd.DataFrame): the dataset with a tokenized text column and a label column\n",
    "            target_x_column (str): the name of the tokenized text column\n",
    "            target_y_column (str): the name of the label column\n",
    "            token_count_cutoff (int): [default=0] the minimum token frequency to add to the\n",
    "                token_vocab.  Any tokens that are less frequent will not be added.\n",
    "        Returns:\n",
    "            SupervisedTextVectorizer: the instantiated vectorizer\n",
    "        \"\"\"\n",
    "        # get the x data (the observations)\n",
    "        target_x_list = df[target_x_column].tolist()\n",
    "        # compute max sequence length, add 2 for the start, end tokens\n",
    "        max_seq_length = max(map(len, target_x_list)) + 2 \n",
    "        \n",
    "        # populate token vocab        \n",
    "        token_vocab = Vocabulary(use_unks=False,\n",
    "                                 use_mask=True,\n",
    "                                 use_start_end=True,\n",
    "                                 start_token=START_TOKEN,\n",
    "                                 end_token=END_TOKEN)\n",
    "        counts = count_tokens(target_x_list)\n",
    "        # sort counts in reverse order\n",
    "        for token, count in sorted(counts.items(), key=lambda x: x[1], reverse=True):\n",
    "            if count < token_count_cutoff:\n",
    "                break\n",
    "            token_vocab.add(token)\n",
    "\n",
    "        # populate label vocab\n",
    "        label_vocab = Vocabulary(use_unks=False, use_start_end=False, use_mask=False)\n",
    "        # add the sorted unique labels \n",
    "        label_vocab.add_many(sorted(df[target_y_column].unique()))\n",
    "        \n",
    "        return cls(token_vocab, label_vocab, max_seq_length)\n",
    "    \n",
    "    def save(self, filename):\n",
    "        \"\"\"Save the vectorizer using json to the file specified\n",
    "        \n",
    "        Args:\n",
    "            filename (str): the output file\n",
    "        \"\"\"\n",
    "        vec_dict = {\"token_vocab\": self.token_vocab.get_serializable_contents(),\n",
    "                    \"label_vocab\": self.label_vocab.get_serializable_contents(),\n",
    "                    'max_seq_length': self.max_seq_length}\n",
    "\n",
    "        with open(filename, \"wb\") as fp:\n",
    "            json.dump(vec_dict, fp)\n",
    "        \n",
    "    @classmethod\n",
    "    def load(cls, filename):\n",
    "        \"\"\"Load the vectorizer from the json file it was saved to\n",
    "        \n",
    "        Args:\n",
    "            filename (str): the file into which the vectorizer was saved.\n",
    "        Returns:\n",
    "            SupervisedTextVectorizer: the instantiated vectorizer\n",
    "        \"\"\"\n",
    "        with open(filename, \"rb\") as fp:\n",
    "            contents = json.load(fp)\n",
    "\n",
    "        contents[\"token_vocab\"] = Vocabulary.deserialize_from_contents(contents[\"token_vocab\"])\n",
    "        contents[\"label_vocab\"] = Vocabulary.deserialize_from_contents(contents[\"label_vocab\"])\n",
    "        return cls(**contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised Text Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SupervisedTextDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Attributes:\n",
    "        vectorizer (SupervisedTextVectorizer): an instantiated vectorizer\n",
    "        active_split (str): the string name of the active split\n",
    "        \n",
    "        # internal use\n",
    "        _split_df (dict): a mapping from split name to partitioned DataFrame\n",
    "        _vectorized (dict): a mapping from split to an x data matrix and y vector\n",
    "        _active_df (pd.DataFrame): the DataFrame corresponding to the split\n",
    "        _active_x (np.ndarray): a matrix of the vectorized text data\n",
    "        _active_y (np.ndarray): a vector of the vectorized labels\n",
    "    \"\"\"\n",
    "    def __init__(self, df, vectorizer, target_x_column, target_y_column):\n",
    "        \"\"\"Initialize the SupervisedTextDataset\n",
    "        \n",
    "        Args:\n",
    "            df (pd.DataFrame): the dataset with a text and label column\n",
    "            vectorizer (SupervisedTextVectorizer): an instantiated vectorizer\n",
    "            target_x_column (str): the column containing the tokenized text\n",
    "            target_y_column (str): the column containing the label\n",
    "        \"\"\"\n",
    "        self._split_df = {\n",
    "            'train': df[df.split=='train'],\n",
    "            'val': df[df.split=='val'],\n",
    "            'test': df[df.split=='test']\n",
    "        }\n",
    "        \n",
    "        self._vectorized = {}\n",
    "        for split_name, split_df in self._split_df.items():\n",
    "            self._vectorized[split_name] = \\\n",
    "                vectorizer.transform(x_data_list=split_df[target_x_column].tolist(), \n",
    "                                     y_label_list=split_df[target_y_column].tolist())\n",
    "        self.vectorizer = vectorizer\n",
    "        self.active_split = None\n",
    "        self._active_df = None\n",
    "        self._active_x = None\n",
    "        self._active_y = None\n",
    "        \n",
    "        self.set_split(\"train\")\n",
    "        \n",
    "    def set_split(self, split_name):\n",
    "        \"\"\"Set the active split\n",
    "        \n",
    "        Args:\n",
    "            split_name (str): the name of the split to make active; should\n",
    "                be one of 'train', 'val', or 'test'\n",
    "        \"\"\"\n",
    "        self.active_split = split_name\n",
    "        self._active_x, self._active_y = self._vectorized[split_name]\n",
    "        self._active_df = self._split_df[split_name]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Return the data point corresponding to the index\n",
    "        \n",
    "        Args:\n",
    "            index (int): an int between 0 and len(self._active_x)\n",
    "        Returns:\n",
    "            dict: the data for this data point. Has the following form:\n",
    "                {\"x_data\": the vectorized text data point, \n",
    "                 \"y_target\": the index of the label for this data point, \n",
    "                 \"x_lengths\": method: the number of nonzeros in the vector,\n",
    "                 \"data_index\": the provided index for bookkeeping}\n",
    "        \"\"\"\n",
    "        return {\n",
    "            \"x_data\": self._active_x[index],\n",
    "            \"y_target\": self._active_y[index],\n",
    "            \"x_lengths\": len(self._active_x[index].nonzero()[0]),\n",
    "            \"data_index\": index\n",
    "        }\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"The length of the active dataset\n",
    "        \n",
    "        Returns:\n",
    "            int: len(self._active_x)\n",
    "        \"\"\"\n",
    "        return self._active_x.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Loading Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def character_tokenizer(input_string):\n",
    "    \"\"\"Tokenized a string a list of its characters\n",
    "    \n",
    "    Args:\n",
    "        input_string (str): the character string to tokenize\n",
    "    Returns:\n",
    "        list: a list of characters\n",
    "    \"\"\"\n",
    "    return list(input_string.lower())\n",
    "\n",
    "def load_surname_dataset(dataset_csv, tokenizer_func, saved_vectorizer_file=None):\n",
    "    \"\"\"Load the surname dataset \n",
    "    \n",
    "    Args:\n",
    "        dataset_csv (str): the location of the dataset\n",
    "        tokenizer_func (function): the tokenizing function to turn each datapoint into \n",
    "            its tokenized form\n",
    "        saved_vectorizer_file (str or None): [default=None] if not None, load the vectorizer\n",
    "            from the file\n",
    "    \"\"\"\n",
    "    df = add_splits(pd.read_csv(dataset_csv), 'nationality')\n",
    "    df['tokenized'] = df.surname.apply(tokenizer_func)\n",
    "    if saved_vectorizer_file is not None:\n",
    "        vectorizer = SupervisedTextVectorizer.load(saved_vectorizer_file)\n",
    "    else:\n",
    "        vectorizer = SupervisedTextVectorizer.from_df(df, \n",
    "                                                      target_x_column='tokenized', \n",
    "                                                      target_y_column='nationality')\n",
    "    dataset = SupervisedTextDataset(df=df, \n",
    "                                    vectorizer=vectorizer, \n",
    "                                    target_x_column='tokenized', \n",
    "                                    target_y_column='nationality')\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify it loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x_data': array([ 1,  9, 12, 13, 19,  7,  8,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0]), 'y_target': 0, 'x_lengths': 8, 'data_index': 0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_surname_dataset(\"../data/surnames.csv\", \n",
    "                               character_tokenizer,\n",
    "                               \"../modelzoo/surnames.vectorizer\")\n",
    "dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_parameter(*size):\n",
    "    \"\"\"Initialize a new parameter\n",
    "    \n",
    "    Args:\n",
    "        size (*args): being star args, pass in any number of ints to create a \n",
    "            parameter tensor of that size.\n",
    "    Returns:\n",
    "        nn.Parameter: a Tensor that has some extra bookkeeping\n",
    "    \"\"\"\n",
    "    out = torch.randn(*size, requires_grad=True, dtype=torch.float32)\n",
    "    torch.nn.init.xavier_normal_(out)\n",
    "    return nn.Parameter(out)\n",
    "\n",
    "def column_gather(y_out, x_lengths):\n",
    "    '''Get a specific vector from each batch datapoint in `y_out`.\n",
    "\n",
    "    More precisely, iterate over batch row indices, get the vector that's at\n",
    "    the position indicated by the corresponding value in `x_lengths` at the row\n",
    "    index.\n",
    "\n",
    "    Args:\n",
    "        y_out (torch.FloatTensor, torch.cuda.FloatTensor)\n",
    "            shape: (batch, sequence, feature)\n",
    "        x_lengths (torch.LongTensor, torch.cuda.LongTensor)\n",
    "            shape: (batch,)\n",
    "\n",
    "    Returns:\n",
    "        y_out (torch.FloatTensor, torch.cuda.FloatTensor)\n",
    "            shape: (batch, feature)\n",
    "    '''\n",
    "    x_lengths = x_lengths.long().detach().cpu().numpy() - 1\n",
    "\n",
    "    out = []\n",
    "    for batch_index, column_index in enumerate(x_lengths):\n",
    "        out.append(y_out[batch_index, column_index])\n",
    "\n",
    "    return torch.stack(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CharBiRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharBiRNN(nn.Module):\n",
    "    def __init__(self, embedding_size, num_embeddings, num_classes, hidden_size, dropout_p=0.5):\n",
    "        \"\"\"Initialize the CharRNN\n",
    "        \n",
    "        Args:\n",
    "            embedding_size (int): size of each embedding vector\n",
    "            num_embeddings (int): number of input characters\n",
    "            num_classes (int): number of characters to predict to\n",
    "            hidden_size (int): the intermediate representation size\n",
    "        \"\"\"\n",
    "        super(CharBiRNN, self).__init__()\n",
    "        \n",
    "        self.emb = nn.Embedding(embedding_dim=embedding_size, \n",
    "                                num_embeddings=num_embeddings, \n",
    "                                padding_idx=0)\n",
    "        \n",
    "        self.rnn = nn.GRU(input_size=embedding_size, \n",
    "                          hidden_size=hidden_size, \n",
    "                          batch_first=True,\n",
    "                          bidirectional=True)\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=hidden_size * 2, \n",
    "                            out_features=hidden_size * 2)\n",
    "        \n",
    "        self.fc2 = nn.Linear(in_features=hidden_size * 2, \n",
    "                             out_features=num_classes)\n",
    "        \n",
    "        self.dropout_p = dropout_p\n",
    "    \n",
    "    \n",
    "    def forward(self, x_in, x_lengths, apply_softmax=False):\n",
    "        \"\"\"The forward pass of the classifier\n",
    "        \n",
    "        Args:\n",
    "            x_in (torch.Tensor): an input data tensor. \n",
    "                x_in.shape should be (batch, input_dim)\n",
    "            x_lengths\n",
    "            apply_softmax (bool): a flag for the softmax activation should \n",
    "                be false if used with the Cross Entropy losses. See note below.\n",
    "        Returns:\n",
    "            torch.FloatTensor: [shape=(batch_size, num_classes)]\n",
    "                The vector for each data point in the batch is \n",
    "                    if `apply_softmax=False`, the pre-softmax prediction vector\n",
    "                    else, the softmax'ed prediction vector\n",
    "        Note:\n",
    "            It is useful to not softmax the prediction vector because there is\n",
    "            a corresponding loss function optimized for it.  In essence, the loss\n",
    "            function associated with optimizing probabilities of multinomials is called\n",
    "            Negative Log Likelihood (NLL). To apply NLL, you first apply the log function.\n",
    "            This function cancels out with the exponential function of the softmax\n",
    "            and so some simplification can occur to shortcut the extra computations. \n",
    "                    \n",
    "        \"\"\"\n",
    "        # x_in.shape == (batch_size, seq_size)\n",
    "        \n",
    "        x_embedded = self.emb(x_in)\n",
    "        # x_embedded.shape == (batch, seq_size, embedding_size)\n",
    "        lengths = x_lengths.detach().cpu().numpy()\n",
    "        x_packed_prernn = torch.nn.utils.rnn.pack_padded_sequence(x_embedded, \n",
    "                                                                  lengths=lengths,\n",
    "                                                                  batch_first=True,\n",
    "                                                                  enforce_sorted=False)\n",
    "        \n",
    "        x_packed_postrnn, _ = self.rnn(x_packed_prernn)\n",
    "        x_post_rnn, _ = torch.nn.utils.rnn.pad_packed_sequence(x_packed_postrnn, \n",
    "                                                               batch_first=True)\n",
    "        # x_post_rnn.shape == (batch_size, seq_size, 2 * hidden_size)\n",
    "        x_post_rnn = x_post_rnn.sum(dim=1) / x_lengths.unsqueeze(dim=1).float()\n",
    "\n",
    "        y_out = F.elu(self.fc1(x_post_rnn))\n",
    "        y_out = self.fc2(F.dropout(y_out, p=self.dropout_p))\n",
    "        \n",
    "\n",
    "        if apply_softmax:\n",
    "            y_out = F.softmax(y_out)\n",
    "            \n",
    "        return y_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prototyping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 18])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(DataLoader(dataset, batch_size=8)))\n",
    "model = CharBiRNN(embedding_size=8, \n",
    "               num_embeddings=len(dataset.vectorizer.token_vocab), \n",
    "               num_classes=len(dataset.vectorizer.label_vocab),\n",
    "               hidden_size=8)\n",
    "model(batch['x_data'], batch['x_lengths']).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(y_pred, y_true):\n",
    "    \"\"\"Compute the accuracy between a matrix of predictions and a vector of label indices\n",
    "    \n",
    "    Args:\n",
    "        y_pred (torch.FloatTensor): [shape=(batch_size, num_classes)]\n",
    "            The matrix of predictions\n",
    "        y_true (torch.FloatTensor): [shape=(batch_size,)]\n",
    "            The vector of label indices\n",
    "    \"\"\"\n",
    "    y_pred_indices = y_pred.argmax(dim=1)\n",
    "    n_correct = torch.eq(y_pred_indices, y_true).sum().item()\n",
    "    return n_correct / len(y_pred_indices) * 100\n",
    "\n",
    "\n",
    "def generate_batches(dataset, batch_size, shuffle=True,\n",
    "                     drop_last=True, device=\"cpu\", dataloader_kwargs=None): \n",
    "    \"\"\"Generate batches from a dataset\n",
    "    \n",
    "    Args:\n",
    "        dataset (torch.utils.data.Dataset): the instantiated dataset\n",
    "        batch_size (int): the size of the batches\n",
    "        shuffle (bool): [default=True] batches are formed from shuffled indices\n",
    "        drop_last (bool): [default=True] don't return the final batch if it's smaller\n",
    "            than the specified batch size\n",
    "        device (str): [default=\"cpu\"] the device to move the tensors to\n",
    "        dataloader_kwargs (dict or None): [default=None] Any additional arguments to the\n",
    "            DataLoader can be specified\n",
    "    Yields:\n",
    "        dict: a dictionary mapping from tensor name to tensor object where the first\n",
    "            dimension of tensor object is the batch dimension\n",
    "    Note: \n",
    "        This function is mostly an iterator for the DataLoader, but has the added\n",
    "        feature that it moves the tensors to a target device. \n",
    "    \"\"\"\n",
    "    dataloader_kwargs = dataloader_kwargs or {}\n",
    "    \n",
    "    dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\n",
    "                            shuffle=shuffle, drop_last=drop_last, **dataloader_kwargs)\n",
    "\n",
    "    for data_dict in dataloader:\n",
    "        out_data_dict = {}\n",
    "        for name, tensor in data_dict.items():\n",
    "            out_data_dict[name] = data_dict[name].to(device)\n",
    "        yield out_data_dict\n",
    "\n",
    "        \n",
    "class TrainState:\n",
    "    \"\"\"A data structure for managing training state operations.\n",
    "    \n",
    "    The TrainState will monitor validation loss and everytime a new best loss\n",
    "        (lower is better) is observed, a couple things happen:\n",
    "        \n",
    "        1. The model is checkpointed\n",
    "        2. Patience is reset\n",
    "    \n",
    "    Attributes:\n",
    "        model (torch.nn.Module): the model being trained and will be\n",
    "            checkpointed during training.\n",
    "        dataset (SupervisedTextDataset, TextSequenceDataset): the dataset \n",
    "            which is being iterate during training; must have the `active_split`\n",
    "            attribute. \n",
    "        log_dir (str): the directory to output the checkpointed model \n",
    "        patience (int): the number of epochs since a new best loss was observed\n",
    "        \n",
    "        # Internal Use\n",
    "        _full_model_path (str): `log_dir/model_state_file`\n",
    "        _split (str): the active split\n",
    "        _best_loss (float): the best observed loss\n",
    "    \"\"\"\n",
    "    def __init__(self, model, dataset, log_dir, model_state_file=\"model.pth\"):\n",
    "        \"\"\"Initialize the TrainState\n",
    "        \n",
    "        Args:\n",
    "            model (torch.nn.Module): the model to be checkpointed during training\n",
    "            dataset (SupervisedTextDataset, TextSequenceDataset): the dataset \n",
    "                which is being iterate during training; must have the `active_split`\n",
    "                attribute. \n",
    "            log_dir (str): the directory to output the checkpointed model \n",
    "            model_state_file (str): the name of the checkpoint model\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.dataset = dataset\n",
    "        self._full_model_path = os.path.join(log_dir, model_state_file)\n",
    "        if not os.path.exists(log_dir):\n",
    "            os.makedirs(log_dir)\n",
    "        self.log_dir = log_dir\n",
    "        \n",
    "        self._metrics_by_split = {\n",
    "            'train': {}, \n",
    "            'val': {}, \n",
    "            'test': {}\n",
    "        }\n",
    "        \n",
    "        self._split = 'train'\n",
    "        self._best_loss = 10**10\n",
    "        self.patience = 0\n",
    "        \n",
    "    def _init_metric(self, split, metric_name):\n",
    "        \"\"\"Initialize a metric to the specified split\n",
    "        \n",
    "        A dictionary is created in `self._metrics_by_split` with\n",
    "            the keys 'running', 'count', and 'history'. \n",
    "        \n",
    "        Args:\n",
    "            split (str): the target split to record the metric\n",
    "            metric_name (str): the name of the metric\n",
    "        \"\"\"\n",
    "        self._metrics_by_split[split][metric_name] = {\n",
    "            'running': 0.,\n",
    "            'count': 0,\n",
    "            'history': []\n",
    "        }\n",
    "        \n",
    "    def _update_metric(self, metric_name, metric_value):\n",
    "        \"\"\"Update a metric with an observed value\n",
    "        \n",
    "        Specifically, the running average is updated.\n",
    "        \n",
    "        Args:\n",
    "            metric_name (str): the name of the metric\n",
    "            metric_value (float): the observed value of the metric\n",
    "        \"\"\"\n",
    "        if metric_name not in self._metrics_by_split[self._split]:\n",
    "            self._init_metric(self._split, metric_name)\n",
    "        metric = self._metrics_by_split[self._split][metric_name]\n",
    "        metric['count'] += 1\n",
    "        metric['running'] += (metric_value - metric['running']) / metric['count']\n",
    "        \n",
    "    def set_split(self, split):\n",
    "        \"\"\"Set the dataset split\n",
    "        \n",
    "        Args:\n",
    "            split (str): the target split to set\n",
    "        \"\"\"\n",
    "        self._split = split\n",
    "        \n",
    "    def get_history(self, split, metric_name):\n",
    "        \"\"\"Get the history of values for any metric in any split\n",
    "        \n",
    "        Args:\n",
    "            split (str): the target split\n",
    "            metric_name (str): the target metric\n",
    "            \n",
    "        Returns:\n",
    "            list(float): the running average of each epoch for `metric_name` in `split` \n",
    "        \"\"\"\n",
    "        return self._metrics_by_split[split][metric_name]['history']\n",
    "    \n",
    "    def get_value_of(self, split, metric_name):\n",
    "        \"\"\"Retrieve the running average of any metric in any split\n",
    "        \n",
    "        Args:\n",
    "            split (str): the target split\n",
    "            metric_name (str): the target metric\n",
    "            \n",
    "        Returns:\n",
    "            float: the running average for `metric_name` in `split`\n",
    "        \"\"\"\n",
    "        return self._metrics_by_split[split][metric_name]['running']\n",
    "        \n",
    "    def log_metrics(self, **metrics):\n",
    "        \"\"\"Log some values for some metrics\n",
    "        \n",
    "        Args:\n",
    "            metrics (kwargs): pass keyword args with the form `metric_name=metric_value`\n",
    "                to log the metric values into the attribute `_metrics_by_split`.\n",
    "        \"\"\"\n",
    "        self._split = self.dataset.active_split\n",
    "        for metric_name, metric_value in metrics.items():\n",
    "            self._update_metric(metric_name, metric_value)\n",
    "            \n",
    "    def log_epoch_end(self):\n",
    "        \"\"\"Log the end of the epoch. \n",
    "        \n",
    "        Some key functions happen at the end of the epoch:\n",
    "            - for each metric in each split running averages, counts, \n",
    "              and history are updated\n",
    "            - the model is checkpointed if a new best value is observed\n",
    "            - patience is incremented if a new best value is not observed\n",
    "        \"\"\"\n",
    "        for split_dict in self._metrics_by_split.values():\n",
    "            for metric_dict in split_dict.values():\n",
    "                metric_dict['history'].append(metric_dict['running'])\n",
    "                metric_dict['running'] = 0.0\n",
    "                metric_dict['count'] = 0\n",
    "                \n",
    "        if 'loss' in self._metrics_by_split['val']:\n",
    "            val_loss = self._metrics_by_split['val']['loss']['history'][-1]\n",
    "            if val_loss < self._best_loss:\n",
    "                self._best_loss = val_loss\n",
    "                self.save_model()\n",
    "                self.patience = 0\n",
    "            else:\n",
    "                self.patience += 1\n",
    "    \n",
    "    def save_model(self):\n",
    "        \"\"\" Save `model` to `log_dir/model_state_file` \"\"\"\n",
    "        torch.save(self.model.state_dict(), self._full_model_path)\n",
    "    \n",
    "    def reload_best(self):\n",
    "        \"\"\" reload `log_dir/model_state_file` to `model` \"\"\"\n",
    "        if os.path.exists(self._full_model_path):\n",
    "            self.model.load_state_dict(torch.load(self._full_model_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA: False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = Namespace(\n",
    "    # dataset\n",
    "    surname_csv=\"../data/surnames.csv\",\n",
    "    # model hyper parameters\n",
    "    embedding_size=100,\n",
    "    hidden_size=100,\n",
    "    num_embeddings=-1,\n",
    "    num_classes=-1,\n",
    "    # training options\n",
    "    batch_size=64,\n",
    "    cuda=False,\n",
    "    learning_rate=0.001,\n",
    "    num_epochs=100,\n",
    "    patience_threshold=3,\n",
    ")\n",
    "\n",
    "\n",
    "# Check CUDA\n",
    "if not torch.cuda.is_available():\n",
    "    args.cuda = False\n",
    "\n",
    "print(\"Using CUDA: {}\".format(args.cuda))\n",
    "\n",
    "args.device = torch.device(\"cuda\" if args.cuda else \"cpu\")\n",
    "args.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus: RAdam, a State-of-the-Art Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "from torch.optim.optimizer import Optimizer, required\n",
    "\n",
    "class RAdam(Optimizer):\n",
    "\n",
    "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0):\n",
    "        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay)\n",
    "        self.buffer = [[None, None, None] for ind in range(10)]\n",
    "        super(RAdam, self).__init__(params, defaults)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        super(RAdam, self).__setstate__(state)\n",
    "\n",
    "    def step(self, closure=None):\n",
    "\n",
    "        loss = None\n",
    "        if closure is not None:\n",
    "            loss = closure()\n",
    "\n",
    "        for group in self.param_groups:\n",
    "\n",
    "            for p in group['params']:\n",
    "                if p.grad is None:\n",
    "                    continue\n",
    "                grad = p.grad.data.float()\n",
    "                if grad.is_sparse:\n",
    "                    raise RuntimeError('RAdam does not support sparse gradients')\n",
    "\n",
    "                p_data_fp32 = p.data.float()\n",
    "\n",
    "                state = self.state[p]\n",
    "\n",
    "                if len(state) == 0:\n",
    "                    state['step'] = 0\n",
    "                    state['exp_avg'] = torch.zeros_like(p_data_fp32)\n",
    "                    state['exp_avg_sq'] = torch.zeros_like(p_data_fp32)\n",
    "                else:\n",
    "                    state['exp_avg'] = state['exp_avg'].type_as(p_data_fp32)\n",
    "                    state['exp_avg_sq'] = state['exp_avg_sq'].type_as(p_data_fp32)\n",
    "\n",
    "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
    "                beta1, beta2 = group['betas']\n",
    "\n",
    "                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
    "                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
    "\n",
    "                state['step'] += 1\n",
    "                buffered = self.buffer[int(state['step'] % 10)]\n",
    "                if state['step'] == buffered[0]:\n",
    "                    N_sma, step_size = buffered[1], buffered[2]\n",
    "                else:\n",
    "                    buffered[0] = state['step']\n",
    "                    beta2_t = beta2 ** state['step']\n",
    "                    N_sma_max = 2 / (1 - beta2) - 1\n",
    "                    N_sma = N_sma_max - 2 * state['step'] * beta2_t / (1 - beta2_t)\n",
    "                    buffered[1] = N_sma\n",
    "\n",
    "                    # more conservative since it's an approximated value\n",
    "                    if N_sma >= 5:\n",
    "                        step_size = math.sqrt((1 - beta2_t) * (N_sma - 4) / (N_sma_max - 4) * (N_sma - 2) / N_sma * N_sma_max / (N_sma_max - 2)) / (1 - beta1 ** state['step'])\n",
    "                    else:\n",
    "                        step_size = 1.0 / (1 - beta1 ** state['step'])\n",
    "                    buffered[2] = step_size\n",
    "\n",
    "                if group['weight_decay'] != 0:\n",
    "                    p_data_fp32.add_(-group['weight_decay'] * group['lr'], p_data_fp32)\n",
    "\n",
    "                # more conservative since it's an approximated value\n",
    "                if N_sma >= 5:            \n",
    "                    denom = exp_avg_sq.sqrt().add_(group['eps'])\n",
    "                    p_data_fp32.addcdiv_(-step_size * group['lr'], exp_avg, denom)\n",
    "                else:\n",
    "                    p_data_fp32.add_(-step_size * group['lr'], exp_avg)\n",
    "\n",
    "                p.data.copy_(p_data_fp32)\n",
    "\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = load_surname_dataset(args.surname_csv, \n",
    "                               tokenizer_func=character_tokenizer)\n",
    "\n",
    "args.num_embeddings = len(dataset.vectorizer.token_vocab)\n",
    "args.num_classes = len(dataset.vectorizer.label_vocab)\n",
    "\n",
    "model = CharBiRNN(embedding_size=args.embedding_size, \n",
    "               hidden_size=args.hidden_size,\n",
    "               num_embeddings=args.num_embeddings,\n",
    "               num_classes=args.num_classes)    \n",
    "\n",
    "# reference: https://github.com/scikit-learn/scikit-learn/blob/7b136e9/sklearn/utils/class_weight.py#L54    \n",
    "class_counts = dataset._split_df['train'].nationality.value_counts().to_dict()\n",
    "total_count = sum(class_counts.values())\n",
    "sorted_counts = sorted(class_counts.items(), \n",
    "                       key=lambda item: dataset.vectorizer.label_vocab[item[0]])\n",
    "class_weights = total_count / torch.tensor([len(sorted_counts) * count for _, count in sorted_counts], dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Routine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a71adbcd2134f7e87ed8b22338bf2b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='epochs', style=ProgressStyle(description_width='initial')), H…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce91bec133b54164b97c1ea621fac1fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='training', max=219, style=ProgressStyle(description_width='in…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efbece538fd9459b850fa765d64bfaa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='validation', max=46, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "342be67ca4634a82bc8ceedae36e194c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='test', max=47, style=ProgressStyle(description_width='initial…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = model.to(args.device)\n",
    "\n",
    "train_state = TrainState(model=model, dataset=dataset, log_dir='./logs/charrnn_classify_surnames',  \n",
    "                         model_state_file='model.pth')\n",
    "\n",
    "optimizer = RAdam(model.parameters(), lr=args.learning_rate, weight_decay=0.0001)\n",
    "\n",
    "# loss function with class-weighted modifications\n",
    "loss_func = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "\n",
    "# progress bars\n",
    "epoch_bar = tqdm_notebook(desc='epochs', total=args.num_epochs, position=1)\n",
    "\n",
    "dataset.set_split(\"train\")\n",
    "train_bar = tqdm_notebook(desc='training', total=len(dataset)//args.batch_size)\n",
    "\n",
    "dataset.set_split(\"val\")\n",
    "val_bar = tqdm_notebook(desc='validation', total=len(dataset)//args.batch_size)\n",
    "        \n",
    "\n",
    "try:\n",
    "    for _ in range(args.num_epochs):\n",
    "        model.train()\n",
    "        dataset.set_split(\"train\")\n",
    "        \n",
    "        for batch in generate_batches(dataset, batch_size=args.batch_size, device=args.device):\n",
    "            # Step 1: clear the gradients \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Step 2: compute the outputs\n",
    "            y_prediction = model(batch['x_data'], batch['x_lengths'])\n",
    "\n",
    "            # Step 3: compute the loss\n",
    "            loss = loss_func(y_prediction, batch['y_target'])\n",
    "            \n",
    "            # Step 4: propagate the gradients\n",
    "            loss.backward() \n",
    "            \n",
    "            # Step 5: update the model weights\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Auxillary: logging\n",
    "            train_state.log_metrics(loss=loss.item(), \n",
    "                                    accuracy=compute_accuracy(y_prediction, batch['y_target']))\n",
    "            \n",
    "            train_bar.set_postfix(loss=train_state.get_value_of(split=\"train\", metric_name=\"loss\"),\n",
    "                                  acc=train_state.get_value_of(split=\"train\", metric_name=\"accuracy\"))\n",
    "            train_bar.update()\n",
    "            \n",
    "        # loop over test dataset\n",
    "        \n",
    "        model.eval()\n",
    "        dataset.set_split(\"val\")\n",
    "        \n",
    "        for batch in generate_batches(dataset, batch_size=args.batch_size, device=args.device):\n",
    "            # Step 1: compute the outputs\n",
    "            y_prediction = model(batch['x_data'], batch['x_lengths'])\n",
    "\n",
    "            # Step 2: compute the loss\n",
    "            loss = loss_func(y_prediction, batch['y_target'])\n",
    "            \n",
    "            # Auxillary: logging\n",
    "            train_state.log_metrics(loss=loss.item(), \n",
    "                                    accuracy=compute_accuracy(y_prediction, batch['y_target']))\n",
    "            \n",
    "            val_bar.set_postfix(loss=train_state.get_value_of(split=\"val\", metric_name=\"loss\"),\n",
    "                                  acc=train_state.get_value_of(split=\"val\", metric_name=\"accuracy\"))\n",
    "            val_bar.update()\n",
    "\n",
    "        \n",
    "        epoch_bar.set_postfix(train_loss=train_state.get_value_of(split=\"train\", \n",
    "                                                                  metric_name=\"loss\"), \n",
    "                              train_accuracy=train_state.get_value_of(split=\"train\", \n",
    "                                                                      metric_name=\"accuracy\"),\n",
    "                              val_loss=train_state.get_value_of(split=\"val\", \n",
    "                                                                metric_name=\"loss\"), \n",
    "                              val_accuracy=train_state.get_value_of(split=\"val\", \n",
    "                                                                    metric_name=\"accuracy\"),\n",
    "                              patience=train_state.patience)\n",
    "        epoch_bar.update()\n",
    "        train_state.log_epoch_end()\n",
    "        train_bar.n = 0\n",
    "        val_bar.n = 0\n",
    "        \n",
    "        if train_state.patience > args.patience_threshold:\n",
    "            break\n",
    "            \n",
    "    train_state.reload_best()\n",
    "    model.eval()\n",
    "    dataset.set_split(\"test\")\n",
    "    test_bar = tqdm_notebook(desc='test', total=len(dataset)//args.batch_size)\n",
    "\n",
    "    for batch in generate_batches(dataset, batch_size=args.batch_size, device=args.device):\n",
    "        # Step 1: compute the outputs\n",
    "        y_prediction = model(batch['x_data'], batch['x_lengths'])\n",
    "\n",
    "        # Step 2: compute the loss\n",
    "        loss = loss_func(y_prediction, batch['y_target'])\n",
    "\n",
    "        # Auxillary: logging\n",
    "        train_state.log_metrics(loss=loss.item(), \n",
    "                                accuracy=compute_accuracy(y_prediction, batch['y_target']))\n",
    "\n",
    "        test_bar.set_postfix(loss=train_state.get_value_of(split=\"test\", metric_name=\"loss\"),\n",
    "                             acc=train_state.get_value_of(split=\"test\", metric_name=\"accuracy\"))\n",
    "        test_bar.update()\n",
    "    \n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fb9b6104390>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_loss_history = train_state.get_history(split='train', metric_name='loss')\n",
    "val_loss_history = train_state.get_history(split='val', metric_name='loss')\n",
    "plt.plot(train_loss_history, label='train loss')\n",
    "plt.plot(val_loss_history, label='val loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fb9ac0e4e80>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_accuracy_history = train_state.get_history(split='train', metric_name='accuracy')\n",
    "val_accuracy_history = train_state.get_history(split='val', metric_name='accuracy')\n",
    "plt.plot(train_accuracy_history, label='train accuracy')\n",
    "plt.plot(val_accuracy_history, label='val accuracy')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_surname(surname):\n",
    "    # surname is lowercased here to match the training data\n",
    "    surname_indices = list(dataset.vectorizer.token_vocab.map(surname.lower(), include_start_end=True))\n",
    "    surname_vector = torch.tensor(surname_indices, dtype=torch.int64).unsqueeze(dim=0)\n",
    "    surname_length = torch.tensor([len(surname_indices)], dtype=torch.int64)\n",
    "    return surname_vector, surname_length\n",
    "    \n",
    "def predict_nationality(model, surname):\n",
    "    model = model.to(\"cpu\")\n",
    "    surname_vector, surname_length = vectorize_surname(surname)\n",
    "    y_prediction = model(surname_vector, surname_length)\n",
    "    _, nationality_index = y_prediction.max(dim=1)\n",
    "    return dataset.vectorizer.label_vocab.lookup(nationality_index.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'japanese'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_nationality(model, 'satoshi nakamoto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'irish'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_nationality(model, 'McMahan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'german'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_nationality(model, 'Bismarck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'english'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_nationality(model, 'Anderson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "magis",
   "language": "python",
   "name": "magis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
